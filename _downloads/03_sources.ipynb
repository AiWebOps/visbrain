{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\nAdd deep sources\n================\n\nAdd sources to the scene. This script also illustrate most of the controls for\nsources. Each source is defined by a (x, y, z) MNI coordinate. Then, we can\nattach some data to sources and project this activity onto the surface\n(cortical projection). Alternatively, you can run the cortical repartition\nwhich is defined as the number of contributing sources per vertex.\n\nDownload source's coordinates (xyz_sample.npz) :\nhttps://www.dropbox.com/s/whogfxutyxoir1t/xyz_sample.npz?dl=1\n\n![](../../picture/picbrain/ex_sources.png)\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n\nfrom visbrain import Brain\nfrom visbrain.objects import SourceObj\nfrom visbrain.io import download_file, path_to_visbrain_data\n\nkwargs = {}\n\n\"\"\"\nLoad the xyz coordinates and corresponding subject name\n\"\"\"\ndownload_file('xyz_sample.npz')\nmat = np.load(path_to_visbrain_data('xyz_sample.npz'))\nxyz, subjects = mat['xyz'], mat['subjects']\n\n\"\"\"\nThe \"subjects\" list is composed of 6 diffrents subjects and here we set one\nunique color (u_color) per subject.\n\"\"\"\nu_color = [\"#9b59b6\", \"#3498db\", \"white\", \"#e74c3c\", \"#34495e\", \"#2ecc71\"]\nkwargs['color'] = [u_color[int(k[1])] for k in subjects]\nkwargs['alpha'] = 0.7\n\n\"\"\"\nNow we attach data to each source.\n\"\"\"\nkwargs['data'] = np.arange(len(subjects))\n\n\"\"\"\nThe source's radius is proportional to the data attached. But this proportion\ncan be controlled using a minimum and maximum radius (s_radiusmin, s_radiusmax)\n\"\"\"\nkwargs['radius_min'] = 2               # Minimum radius\nkwargs['radius_max'] = 15              # Maximum radius\nkwargs['edge_color'] = (1, 1, 1, 0.5)  # Color of the edges\nkwargs['edge_width'] = .5              # Width of the edges\nkwargs['symbol'] = 'square'            # Source's symbol\n\n\"\"\"\nNext, we mask source's data that are comprised between [20, 40] and color\neach source to orange\n\"\"\"\nmask = np.logical_and(kwargs['data'] >= 20., kwargs['data'] <= 40)\nkwargs['mask'] = mask\nkwargs['mask_color'] = 'orange'\n\n\"\"\"\nAfter defining sources, it's possible to run the cortical projection and/or the\ncortical repartition. The lines bellow are used to control the colormap when\nopening the interface.\nRun the projection from the menu Project/Run projection, from the source's tab\nor using the shortcut CTRL + P (for projection) or CTRL + R (repartition)\n\nUse CTRL + D to hide/display the quick-settings panel, the shortcut C to\ndisplay the colorbar.\n\"\"\"\nkw_proj = dict(project_radius=12.,\n               project_contribute=True,\n               project_mask_color='orange',\n               project_cmap='viridis',\n               project_clim=(kwargs['data'].min(), kwargs['data'].max()),\n               project_vmin=20,\n               project_vmax=500,\n               project_under='gray',\n               project_over='red'\n               )\n\n\"\"\"\nIt's also possible to add text to each source. Here, we show the name of the\nsubject in yellow.\nTo avoid a superposition between the text and sources sphere, we introduce an\noffset to the text using the s_textshift input\n\"\"\"\nkwargs['text'] = subjects              # Name of the subject\nkwargs['text_color'] = \"#f39c12\"       # Set to yellow the text color\nkwargs['text_size'] = 1.5              # Size of the text\nkwargs['text_translate'] = (1.5, 1.5, 0)\nkwargs['text_bold'] = True\n\n\"\"\"Create the source object. If you want to previsualize the result without\nopening Brain, use s_obj.preview()\n\"\"\"\ns_obj = SourceObj('SourceExample', xyz, **kwargs)\n# s_obj.preview()\n\n# Pass all arguments in the dictionnary :\nvb = Brain(source_obj=s_obj, brain_template='B3', **kw_proj)\nvb.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}